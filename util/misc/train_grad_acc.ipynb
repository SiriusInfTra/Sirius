{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "data = torchvision.datasets.CIFAR10(root='/disk2/wjl/cv-dataset', \n",
    "                                    train=True, download=False, transform=train_transform)\n",
    "train_dataset, val_dataset, _ = torch.utils.data.random_split(data, [40000, 10000, 0]) # total 50000\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='/disk2/wjl/cv-dataset',\n",
    "                                            train=False, download=False, transform=test_transform)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils\n",
    "\n",
    "class GradAccDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, dataset, global_batch_size, max_batch_size, random_batch_size):\n",
    "        self.dataset = dataset\n",
    "        self.loader = torch.utils.data.DataLoader(dataset, batch_size=global_batch_size, shuffle=True)\n",
    "        self.global_batch_size = global_batch_size\n",
    "        self.max_batch_size = max_batch_size\n",
    "        self.random_batch_size = random_batch_size\n",
    "        self.gb = None\n",
    "        self.gb_idx = 0\n",
    "        self.lb_idx = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.gb = None\n",
    "        self.gb_idx = 0\n",
    "        self.lb_idx = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def _next_gb(self):\n",
    "        while True:\n",
    "            for b in self.loader:\n",
    "                yield b\n",
    "\n",
    "    def next_gb(self):\n",
    "        assert self.gb_idx != len(self)\n",
    "        next_gb_size = min(self.global_batch_size, len(self)-self.gb_idx)\n",
    "        # self.gb = next(self.loader)\n",
    "        self.gb = next(self._next_gb())\n",
    "        imgs, labs = self.gb\n",
    "        assert len(imgs) == next_gb_size\n",
    "        self.lb_idx = 0\n",
    "        self.gb_idx += next_gb_size\n",
    "    \n",
    "    def __iter__(self):\n",
    "        worker_info = torch.utils.data.get_worker_info()\n",
    "        assert worker_info is None, \"This dataset is not compatible with multi-process loading\"\n",
    "        while True:\n",
    "            if self.gb is None or self.lb_idx >= len(self.gb[0]):\n",
    "                if self.gb_idx == len(self):\n",
    "                    self.reset()\n",
    "                    break\n",
    "                self.next_gb()                \n",
    "\n",
    "            imgs, labs = self.gb\n",
    "\n",
    "            if self.random_batch_size:\n",
    "                batch_size = torch.randint(1, self.max_batch_size+1, (1,)).item()\n",
    "            else:\n",
    "                batch_size = self.max_batch_size\n",
    "\n",
    "            batch_size = min(len(imgs)-self.lb_idx, batch_size)\n",
    "            lb = (imgs[self.lb_idx:self.lb_idx+batch_size], labs[self.lb_idx:self.lb_idx+batch_size])\n",
    "            self.lb_idx += batch_size\n",
    "            assert self.lb_idx <= len(imgs)\n",
    "            assert batch_size > 0\n",
    "            yield lb\n",
    "        \n",
    "        # return torch.utils.data.DataLoader(self.dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    def can_step(self):\n",
    "        imgs, _ = self.gb\n",
    "        # print(self.gb_idx, self.lb_idx, self.lb_idx == len(imgs))\n",
    "        return self.lb_idx == len(imgs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_batch_size = True\n",
    "\n",
    "global_batch_size = 500\n",
    "max_batch_size = 100\n",
    "\n",
    "train_dataset = GradAccDataset(train_dataset, global_batch_size, max_batch_size, random_batch_size)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=None, shuffle=None, \n",
    "                                               num_workers=0, drop_last=False)\n",
    "\n",
    "# train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=80, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=80, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.base = torchvision.models.swin_t()\n",
    "        self.fc = nn.Linear(1000, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, \n",
    "                            momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0 loss 2.1 acc 22.8% val acc 26.8%] 216.4 sec, thpt 184.8\n",
      "[epoch 1 loss 2.0 acc 27.9% val acc 29.1%] 219.8 sec, thpt 182.0\n",
      "[epoch 2 loss 1.9 acc 31.0% val acc 31.8%] 214.3 sec, thpt 186.7\n",
      "[epoch 3 loss 1.8 acc 33.3% val acc 32.8%] 214.2 sec, thpt 186.7\n",
      "[epoch 4 loss 1.8 acc 34.8% val acc 35.9%] 213.5 sec, thpt 187.4\n",
      "[epoch 5 loss 1.8 acc 36.7% val acc 37.0%] 214.5 sec, thpt 186.5\n",
      "[epoch 6 loss 1.7 acc 37.9% val acc 38.8%] 211.4 sec, thpt 189.2\n",
      "[epoch 7 loss 1.7 acc 39.6% val acc 39.4%] 213.7 sec, thpt 187.2\n",
      "[epoch 8 loss 1.6 acc 40.5% val acc 40.8%] 213.3 sec, thpt 187.6\n"
     ]
    }
   ],
   "source": [
    "epoch = 10\n",
    "\n",
    "model.train()\n",
    "\n",
    "for e in range(epoch):\n",
    "    running_loss = 0\n",
    "    running_acc = 0\n",
    "\n",
    "    epoch_begin_t = time.time()\n",
    "    for i, b in enumerate(train_dataloader):\n",
    "        images, labels = b\n",
    "        lbs = len(images)\n",
    "        # print(len(images))\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        scaled_loss = loss * lbs / global_batch_size\n",
    "        scaled_loss.backward()\n",
    "        \n",
    "        if train_dataset.can_step():\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        pred = torch.argmax(output.detach(), dim=1)\n",
    "        running_acc += (pred == labels).sum().item()\n",
    "    epoch_end_t = time.time()\n",
    " \n",
    "    val_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for i, b in enumerate(val_dataloader):\n",
    "            images, labels = b\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            output = model(images)\n",
    "            \n",
    "            pred = torch.argmax(output, dim=1)\n",
    "            val_acc += (pred == labels).sum().item()\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_train_acc = 100 * running_acc / len(train_dataset)\n",
    "    epoch_val_acc = 100 * val_acc / len(val_dataset)\n",
    "    train_thpt = len(train_dataset) / (epoch_end_t - epoch_begin_t)\n",
    "    epoch_time = epoch_end_t - epoch_begin_t\n",
    "    print(f'[epoch {e} loss {epoch_loss:.1f} acc {epoch_train_acc:.1f}% val acc {epoch_val_acc:.1f}%] {epoch_time:.1f} sec, thpt {train_thpt:.1f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colserve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
